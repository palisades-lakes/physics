\begin{plSection}{Registration}
\label{sec:registration}

This section discusses functions that are minimized
to register (align) one mesh to another,
to register a mesh to a data set,
or to register a data set to a mesh.
The general approach is to minimize
a measure of distance between the {\it docking} mesh and its {\it target},
over some set of registration transforms,
for example, the rigid transformations of $\Reals^3$.

We most often compute a registration transform, $\Vector{T}$,
to minimize a distance between the transformed mesh,
$\Vector{T}\Set{M}$ and its target, $\Set{T}$:
\begin{equation}
\min_{\Vector{T}} d(\Set{M}(\Vector{T}),\Set{T})
\end{equation}
The target, $\Set{T}$, may be another mesh, a set of data points,
or some other geometric object.
The transformed mesh
$\Set{M}(\Vector{T})
 = \Set{M}(\Vector{T}\Vector{v}) 
 = \Set{M}(\Vector{T}(\Vector{v}_0 \ldots \Vector{v}_{n-1}))$,
where $\Vector{v} = (\Vector{v}_0 \ldots  \Vector{v}_{n-1})$
are the positions of the vertices of $\Set{M}$.

We are also sometimes interested in registering a data set
$\left\{ \Vector{x}_i \right\}$ to a mesh.
In this case, we minimize
\begin{equation}
\min_{\Vector{T}} d(\Set{M},\Vector{T}\left\{\Vector{x}_i\right\})
\end{equation}

Both are special cases of choosing a transform on $\Reals^{3n}$
by minimizing:
\begin{equation}
\min_{\Vector{T}} f( \Vector{T} \Vector{p}),
\end{equation}
where
$\Vector{p} = (\Vector{p}_0 \ldots  \Vector{p}_{n-1}) \in \Reals^{3n}$,
$\Vector{T} : \Reals^{3n} \mapsto \Reals^{3n}$,
and
$f : \Reals^{3n} \mapsto \Reals$.

%-----------------------------------------------------------------
\begin{plSection}{Distance measures}
\label{sec:Distance-measures}

%-----------------------------------------------------------------
\begin{plSection}{Vertex distance}
\label{sec:Vertex-distance}

\textbf{TODO:} Re-write with one set of vertices and $2$
embedding functions.

Suppose $2$ meshes have corresponding vertices,
that is,
for each vertex $\Vector{v}_{0i}$ in the docking mesh $\Set{M}_0$,
there is a corresponding vertex $\Vector{v}_{1i}$ 
in the target mesh $\Set{M}_1$,
and vice versa (same abstract mesh).
Then an obvious measure of distance
is the sum of distances between the corresponding points:
\begin{equation}
d_{\Set{V}}(\Set{M}_0,\Set{M}_1) = 
\sum_{i=0}^{n-1} \| \Vector{p}_{0i} - \Vector{p}_{1i} \|^2
\end{equation}
The gradient of $d_{\Set{V}}$ with respect to the positions
of the $i$th vertex of $\Set{M}_0$ is:
\begin{equation}
\Gradient[\Vector{p}_{0i}]{d_{\Set{V}}}[q] = 
2 \left[ \Vector{q}_{0i} - \Vector{p}_{1i} \right]
\end{equation}

\end{plSection}%{Vertex distance}
%-----------------------------------------------------------------
\begin{plSection}{Projection distance}
\label{sec:Projection-distance}

In many problems, the vertex correspondence used in
\cref{sec:Vertex-distance} is not appropriate.
Or we may want to register a mesh to a target data set.
In such cases, we can use the projection distance:
\begin{equation}
d_{\Pr}(\Set{M},\Vector{p}_1) 
= \sum_{i=0}^{n-1} \| 
\Pr_{\Set{M}}(\Vector{p}_{1i}) - \Vector{p}_{1i} \|^2,
\end{equation}
where the target 
$\Vector{p}_1 = (\Vector{p}_{10}, \ldots \Vector{p}_{1(n-1)})$
is either a set of data points,
or the set of positions of the vertices of a target mesh.
$\Pr_{\Set{M}}(\Vector{p})$ is the projection of the point 
$\Vector{p} \in \Reals^3$
on the mesh $\Set{M}$.
This is the same as the general data fitting distance, and
derivatives with respect to the positions of the vertices
of $\Set{M}$ are given in \cref{sec:data-fitting}.

\end{plSection}%{Projection distance}
%-----------------------------------------------------------------
\end{plSection}%{Distance measures}
%-----------------------------------------------------------------
\begin{plSection}{Transforms}
\label{sec:Transforms}

In this section, I describe common families
of transforms, $\left\{\Vector{T}\right\}$, over which to minimize:
\begin{equation}
\min_{\Vector{T}} f( \Vector{T} \Vector{p}),
\end{equation}
To do the minimization, we need to compute
the derivative:
\begin{equation}
\Derivative[\Vector{T}]{g(\Vector{T})}[\Vector{T}_0]
= \Derivative[\Vector{T}]{f(\Vector{T}\Vector{p})}[\Vector{T}_0]
= \Derivative[\Vector{q}]{f(\Vector{q})}[\Vector{q}=\Vector{T}_0\Vector{p}]
\circ
\Derivative[\Vector{T}]{\Vector{T}\Vector{p}}[\Vector{T}_0].
\end{equation}
o, equivalently, the gradient:
\begin{equation}
\Gradient[\Vector{T}]{f( \Set{M}(\Vector{T}\Vector{p}) )}[\Vector{T}_0]
 =
\Derivative[\Vector{T}]{\Vector{T}\Vector{p}}[\Vector{T}_0]^\dagger
\Gradient[\Vector{q}]{f(\Set{M}(\Vector{q})))}[\Vector{T}_0\Vector{p}]
\end{equation}

I assume in the following
that 
$\Derivative[\Vector{p}]{f}$ (or $\Gradient{\Vector{p}}[f]$) is known,
so the main task is computing 
$\Derivative[\Vector{T}]{\Vector{T}\Vector{p}}$.

As mentioned in above,
in registration problems
the function $f$ is usually a distance between
two meshes, or between a mesh and a data set,
with either the location of one mesh's vertices
or the data points allowed to vary.
Derivatives and gradients of distance functions,
with respect to vertex positions,
are given in sections \ref{sec:Distance-measures}
and \ref{sec:data-fitting}.
%-----------------------------------------------------------------
\begin{plSection}{Direct sum transforms}
\label{sec:Direct-sum-transforms}

In registration problems,we usually want to
apply the same transform to each vertex or data point.
Let $\Vector{T} : \Reals^3 \mapsto \Reals^3$ be an element
of some family of transformations on $\Reals^3$.
A simple direct sum transform applies the same 3-dimensional
transform to each vertex point,
so the full mesh transform is
$\Vector{T}_{3n} = \bigoplus^n \Vector{T}$,
and $\Vector{T}_{3n} (\bigoplus_{i=0}^{n-1} \Vector{p}_i) = \bigoplus_{i=0}^{n-1} \Vector{T} \Vector{p}_i$
by transforming the locations of each of the vertices
of the mesh.

In general, suppose $\Vector{T}_i :
{\mathcal D}_i \mapsto {\mathcal C}_i; i = 0 \ldots k-1$
are $k$ maps.
The direct sum of the $\Vector{T}_i$ is:
\begin{equation}
\label{eq:diagonal-blocks}
\Vector{T} =
\left( \bigoplus_{i=0}^{k-1} \Vector{T}_i \right) :
\left( \bigoplus_{i=0}^{k-1}{\mathcal D}_i \right)
\mapsto
\left( \bigoplus_{i=0}^{k-1}{\mathcal C}_i \right)
\end{equation}
$\Vector{T}$ is a transform whose
$k$ 'diagonal blocks' are the $\Vector{T}_i$.

Using this notation,
$\Derivative[\Vector{p}]{f(\Vector{p})} 
= \bigoplus_i \Derivative[\Vector{p}_i]{f(\Vector{p})}$,
$\Derivative[\Vector{T}]{\Vector{T}\Vector{p}} 
= \bigoplus_i \Derivative[\Vector{T}]{\Vector{T}\Vector{p}_i}$,
and:
\begin{equation}
\label{eq:total-registration-transform-derivative}
\Derivative[\Vector{T}]{f( \Vector{T} \Vector{p} )}[\Vector{T}_0]
 =
\sum_i
\Derivative[\Vector{q}_i]{f(\Vector{q})}[\Vector{q}=\Vector{T}_0\Vector{p}]
\circ
\Derivative[\Vector{T}]{\Vector{T}\Vector{p}_i}[\Vector{T}_0]
\end{equation}
For the gradient, the equivalent is:
\begin{equation}
\label{eq:registration-gradient-sum}
\Gradient[\Vector{T}]{f( \Vector{T} \Vector{p} )}[\Vector{T}_0]
 =
\sum_i
\left( \Derivative[\Vector{T}]{\Vector{T}\Vector{p}_i}[\Vector{T}_0] \right)^{\dagger} \;
\left( \Gradient[\Vector{q}_i]{f(\Vector{q})}[\Vector{q}=\Vector{T}_0\Vector{p}] \right)
\end{equation}

The derivative with respect to vertex or data points,
$\Derivative[\Vector{p}_i]{f(\Vector{p})}$,
is assumed to be known.
For example, the derivatives of functions
related to data fitting
are discussed in chapter \ref{sec:data-fitting}.

In this chapter, I focus on computing
$\Derivative[\Vector{T}]{\Vector{T}\Vector{p}}[\Vector{T}_0]$
for $\Vector{T} : \Reals^3 \mapsto \Reals^3$
and $\Vector{p} \in \Reals^3$.

\end{plSection}%{Direct sum transforms}
%-----------------------------------------------------------------
\begin{plSection}{General linear registration}
\label{sec:General-linear-registration}

Suppose $\Vector{T} = \Vector{L}$ a linear transform on $\Reals^3$.
We can represent $\Vector{L}$ as a vector in $\Reals^9$:
\begin{equation}
\label{eq:L-vector}
\Vector{l} = \left(\Vector{L}_{00},\Vector{L}_{01},\Vector{L}_{02},
       \Vector{L}_{10},\Vector{L}_{11},\Vector{L}_{12},
       \Vector{L}_{20},\Vector{L}_{21},\Vector{L}_{22}\right),
\end{equation}
where $\Vector{L}_{ij}$ is the $ij$-th element of a
matrix representation of $\Vector{L}$.
We can identify a vector $\Vector{p} \in \Reals^3$
with a linear transform 
$\Vector{T}_{\Vector{p}} : \Reals^9 \mapsto \Reals^3$
by defining 
$\Vector{T}_{\Vector{p}}\Vector{l} = \Vector{L}\Vector{p}$.
In the coordinate system defined by \cref{eq:L-vector},
the matrix for $\Vector{T}_{\Vector{p}}$ is:
\begin{equation}
\label{eq:Tp-matrix}
\Vector{T}_{\Vector{p}} =
\left(
\begin{array}{lllllllll}
\Vector{p}_0 & \Vector{p}_1 & \Vector{p}_2 &  0   &  0   &  0   &  0   &  0   &  0 \\
 0   &  0   &  0   & \Vector{p}_0 & \Vector{p}_1 & \Vector{p}_2 &  0   &  0   &  0 \\
 0   &  0   &  0   &  0   &  0   &  0   & \Vector{p}_0 & \Vector{p}_1 & \Vector{p}_2 \\
\end{array}
\right)
\end{equation}

Because linear transforms are their own derivatives
(see section\ref{sec:Derivatives-of-linear-functions}),
it follows that the derivative with respect to the
unconstrained set of linear registration transforms is:
\begin{equation}
\label{eq:linear-transform-derivative}
\Derivative[\Vector{L}]{\left( \Vector{L} \, \Vector{p} \right)}
 \; = \;
\Derivative[\Vector{L}]{\left( \Vector{T}_{\Vector{p}} \, \Vector{L} \right)}
 \; = \;
\Vector{T}_{\Vector{p}}
\end{equation}

\end{plSection}%{General linear registration}
%-----------------------------------------------------------------
\begin{plSection}{Scaled rotations}
\label{sec:Scaled-rotations}

A scaled rotation
is a linear transform $\Vector{S} = s \Vector{R}$,
where $s \in \Reals$ and $\Vector{R} : \Reals^n \mapsto \Reals^n$
is a rotation.

The quaternions $\Set{Q}$ are a convenient representation
for the scaled rotations on $\Reals^3$.
(See Faugeras~\cite[sec.~5.5.2]{Faugeras:1993:3dVision}.)

A quaternion is a 4-tuple:
\begin{equation}
\Vector{q} = (w, x, y, z) = (w, \Vector{v}),
\end{equation}
where $w, x, y, z \in \Reals$ and $\Vector{v} \in \Reals^3$.
The set of quaternions has several operations:
\begin{itemize}
\item Quaternion conjugation $\dagger$:
\begin{equation}
\Vector{q}^\dagger = (w, \Vector{v})^\dagger = (w, - \Vector{v})
\end{equation}
\item The quaternion product $\diamond$:
\begin{equation}
\Vector{q}_0 \diamond \Vector{q}_1 = (w_0w_1 - \Vector{v}_0 \bullet \Vector{v}_1, w_0 \Vector{v}_1 + w_1 \Vector{v}_0 + \Vector{v}_0 \times \Vector{v}_1)
\end{equation}
\item Quaternion norm $\| \|_{\Set{Q}}$:
\begin{equation}
\| \Vector{q} \|_{\Set{Q}}^2
= \Vector{q}^\dagger \bullet \Vector{q}
= \Vector{q} \bullet \Vector{q}^\dagger
= w^2 + \|\Vector{v}\|^2
= w^2 + x^2 + y^2 + z^2
\end{equation}
\end{itemize}

The quaternion product can be extended to $\Reals^3$
by identifying $\Vector{p} \in \Reals^3$ with
the quaternion $(0,\Vector{p})$.
This allows us to define a linear transform
on $\Reals^3$ for any quaternion:
\begin{equation}
\Vector{S}(\Vector{q}) \Vector{p} = \Vector{q} \diamond \Vector{p} \diamond \Vector{q}^\dagger
\end{equation}

It turns out that transforms $\Vector{S}(\Vector{q})$ so defined are scaled rotations.
The scale is the squared norm of the quaternion $\| \Vector{q} \|_{\Set{Q}}^2$.
The rotation is about the axis of $\Vector{v}$
by $\cos^{-1}(w / \| \Vector{q} \|_{\Set{Q}})$.
(Note that $\Vector{q}$ and $-\Vector{q}$ correspond to the same scaled rotation.)

$\Vector{S}(\Vector{q})$ can be written as a matrix:
\begin{equation}
\label{eq:quaternion-matrix}
\Vector{S}(\Vector{q}) =
\left(
\begin{array}{ccc}
w^2 + x^2 - y^2 - z^2 & 2(xy - wz)            & 2(xz + wy)           \\
2(xy + wz)            & w^2 - x^2 + y^2 - z^2 & 2(yz - wx)           \\
2(xz - wy)            & 2(yz + wx)            & w^2 - x^2 - y^2 +z^2
\end{array}
\right)
\end{equation}

Notice that the adjoint (transpose) of $\Vector{S}(\Vector{q})$
is the linear transform corresponding to the conjugate quaternion:
$\Vector{S}^{\dagger}(\Vector{q}) =  \Vector{S}(\Vector{q}^{\dagger})$.

If we consider $\Vector{S}(\Vector{q})$ to be a 9-dimensional vector,
as in \cref{eq:L-vector},
then the derivative can be expressed as the matrix:
\begin{equation}
\label{eq:quaternion-derivative-matrix}
\Derivative[q]{\Vector{S}(\Vector{q})}
 = 2 \left(
\begin{array}{rrrr}
  w &  x & -y & -z \\
  z &  y &  x &  w \\
 -y &  z & -w &  x \\
 -z &  y &  x & -w \\
  w & -x &  y & -z \\
  x &  w &  z &  y \\
  y &  z &  w &  x \\
 -z & -w &  z &  y \\
  w & -x & -y &  z \\
\end{array}
\right)
\end{equation}

It's also useful to express the derivative $\Derivative[q]{\Vector{S}(\Vector{q})}$
as a set of partial derivative matrices,
which are computed
by differentiating the elements of matrix in equation
\ref{eq:quaternion-matrix}:
\begin{eqnarray}
\label{eq:quaternion-matrix-partial-derivatives}
\Derivative[w]{\Vector{S}(\Vector{q})}
& = &
2 \left(
\begin{array}{rrr}
 w & -z &  y \\
 z &  w & -x \\
-y &  x &  w
\end{array}
\right)
\\
\nonumber
\\
\Derivative[x]{\Vector{S}(\Vector{q})}
& = &
2 \left(
\begin{array}{rrr}
 x &  y &  z \\
 y & -x & -w \\
 z &  w & -x
\end{array}
\right)
\nonumber
\\
\nonumber
\\
\Derivative[y]{\Vector{S}(\Vector{q})}
& = &
2 \left(
\begin{array}{rrr}
-y &  x &  w \\
 x &  y &  z \\
-w &  z & -y
\end{array}
\right)
\nonumber
\\
\nonumber
\\
\Derivative[z]{\Vector{S}(\Vector{q})}
& = &
2 \left(
\begin{array}{rrr}
-z & -w &  x \\
 w & -z &  y \\
 x &  y &  z
\end{array}
\right)
\nonumber
\end{eqnarray}

Note that
$\Derivative[w]{\left( \Vector{S}(\Vector{q}) \; \Vector{p} \right)}
 = \left( \Derivative[w]{\Vector{S}(\Vector{q})}\right) \; \Vector{p}$
(and similarly for the partials with respect to $x,y,$ and $z$).

We can write the total derivative in terms of the partials as:
\begin{eqnarray}
\Derivative[\Vector{q}]{\left( \Vector{S}(\Vector{q}) \; \Vector{p} \right)}
& = &
\left( \Derivative[w]{\Vector{S}(\Vector{q})} \; \Vector{p} \right) \otimes \Vector{e}_w
\\
& + &
\left( \Derivative[x]{\Vector{S}(\Vector{q})} \; \Vector{p} \right) \otimes \Vector{e}_x
\nonumber
\\
& + &
\left( \Derivative[y]{\Vector{S}(\Vector{q})} \; \Vector{p} \right) \otimes \Vector{e}_y
\nonumber
\\
& + &
\left( 
\Derivative[z]{\Vector{S}(\Vector{q})} \; \Vector{p} \right) 
\otimes \Vector{e}_z
\nonumber
\end{eqnarray}

In computing the gradients of registration penalties,
we sum expressions like
$\Derivative[\Vector{q}]
{\left( \Vector{S}(\Vector{q})\Vector{p}_i \right)}^{\dagger} \;
\Gradient[\Vector{p}_i]{f}$
(see \cref{eq:registration-gradient-sum}).
In terms of the partial derivative matrices,
this is:
\begin{equation}
\Derivative[\Vector{q}]
{\left( \Vector{S}(\Vector{q})\Vector{p}_i \right)}^{\dagger} \;
\Gradient[\Vector{p}_i]{f}
=
\left(
\begin{array}{c}
\left( \Derivative[w]{\Vector{S}(\Vector{q})} 
\; \Vector{p} \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[x]{\Vector{S}(\Vector{q})} 
\; \Vector{p} \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[y]{\Vector{S}(\Vector{q})} 
\; \Vector{p} \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[z]{\Vector{S}(\Vector{q})} 
\; \Vector{p} \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\end{array}
\right)
\end{equation}

We sometimes encounter the inverse transform, 
$\Vector{S}^{-1}(\Vector{q})$,
which is the same as the linear transform,
$\Vector{S}(\Vector{q}^{-1})$,
corresponding to the inverse quaternion
(in the sense of the quaternion product):
$\Vector{q}^{-1} = (w, x, y, z)^{-1}
= \frac{1}{\|\Vector{q}\|_{\Set{Q}}^2} (w, -x, -y, -z)$.

To compute derivatives of expressions
involving an inverse quaternion,
we can use the derivative of $\Vector{q}^{-1}$
with respect to $\Vector{q}$:
\begin{equation}
\Derivative[\Vector{q}]{\Vector{q}^{-1}}
=
\frac{1}{\|\Vector{q}\|_{\Set{Q}}^4}
\left(
\begin{array}{cccc}
-w^2+x^2+y^2+z^2 & -2wx              & -2wy              & -2wz \\
 2wx             & -w^2+x^2-y^2-z^2  &  2xy              &  2xz \\
 2wy             &   2xy             & -w^2-x^2+y^2-z^2  &  2yz \\
 2wz             &   2xz             &  2yz              &  -w^2-x^2-y^2+z^2 \\
\end{array}
\right)
\end{equation}

\end{plSection}%{Scaled rotations}
%-----------------------------------------------------------------
\begin{plSection}{Rotations}
\label{sec:Rotations}

A common representation for the rotations on $\Reals^3$
is the set of {\it unit quaternions},
that is, the quaternions satisfying $\| \Vector{q} \|_{\Set{Q}} = 1$.
However, optimization under a nonlinear constraint
like $\| \Vector{q} \|_{\Set{Q}} = 1$ is relatively difficult,
so I instead use a redundant representation by general quaternion:
\begin{equation}
\Vector{R}(\Vector{q}) = 
\frac{\Vector{S}(\Vector{q})}
{\| \Vector{q} \|_{\Set{Q}}^2}
\end{equation}
To avoid numerical instability, it's usually enough
to add a small penalty for $\| \Vector{q} \|_{\Set{Q}}$ far from $1$.

The partial derivative matrices of $\Vector{R}(\Vector{q})$ are used in the
same way as,
and can be expressed in terms of,
the partials of $\Vector{S}(\Vector{q})$:
\begin{equation}
\Derivative[v]{\Vector{R}(\Vector{q})}
\; = \;
\Derivative[v]
{\left(
\frac{\Vector{S}(\Vector{q})}{\| \Vector{q} \|_{\Set{Q}}^2}
\right)}
\; = \;
\frac{\Derivative[v]{\Vector{S}(\Vector{q})}}
{\| \Vector{q} \|_{\Set{Q}}^2}
-
\frac{2v \Vector{S}(\Vector{q})}{\| \Vector{q} \|_{\Set{Q}}^4}
\end{equation}
where $v$ is any of $w$, $x$, $y$, or $z$.

\end{plSection}%{Rotations}
%-----------------------------------------------------------------
\begin{plSection}{Shift registration}
\label{sec:Shift-registration}

A simple shift, or translation, adds a constant vector
to its argument: $\Vector{T} \Vector{p} = \Vector{p} + \Vector{t},$
for some $\Vector{t} \in \Reals^3$.
The derivative with respect to
an unconstrained translation vector
is simply
$\Derivative[\Vector{t}]
{(\Vector{p} + \Vector{t})} 
= \Identity_{\Reals^3},$
where $\Identity_{\Reals^3}$ is the identity on $\Reals^3$.

\end{plSection}%{Shift Registration}
%-----------------------------------------------------------------
\begin{plSection}{Affine registration}
\label{sec:affine-registration}

An {\it affine transformation,} $\Vector{A} : \Reals^m \mapsto \Reals^n$,
is a linear transformation plus a translation:
$\Vector{A} \Vector{p} = \Vector{L} \Vector{p} + \Vector{t}$,
where $\Vector{L} : \Reals^m \mapsto \Reals^n$ is a linear transform,
the {\it linear part} of the affine tranform,
and $\Vector{t} \in \Reals^n$ is $\Vector{A}$'s {\it translation}.

Note that, if $\Vector{A} = (\Vector{L},\Vector{t})$, then its inverse is
$\Vector{A}^{-1} = (\Vector{L}^{-1}, - \Vector{L}^{-1}\Vector{t})$.

(It is sometimes useful to use a redundant representation:
$\Vector{A} \Vector{p} 
= \Vector{L} (\Vector{p} + \Vector{t}_0) + \Vector{t}_1$,
where $\Vector{t}_0 \in \Reals^m$ and $\Vector{t}_1 \in \Reals^n$,
but, for simplicity, I'll stick to the minimal one-translation
representation in this discussion.)

In the context of mesh registration,
where $\Vector{A} : \Reals^3 \mapsto \Reals^3$,
we can view $\Vector{L} \in \Reals^9$ and
$\Vector{A} = (\Vector{L}, \Vector{t}) \in \left(\Reals^9 \oplus \Reals^3 \right)= \Reals^{12}$,
and we can express derivatives with respect to $\Vector{A}$
in terms of the independent partial derivatives
with respect to $\Vector{L}$ and $\Vector{t}$.

It follows from the results in the preceding sections,
that the derivative with respect to the
unconstrained set of affine registration transforms is:
\begin{equation}
\label{eq:affine-transform-derivative}
\Derivative[(\Vector{L},\Vector{t})]{\left( \Vector{A} \, \Vector{p} \right)}
 \; = \;
\Derivative[(\Vector{L},\Vector{t})]{\left( \Vector{L} \Vector{p} + \Vector{t} \right)}
 \; = \;
\Vector{T}_{\Vector{p}} \oplus _{\Reals^3},
\end{equation}
where $\oplus$ indicates,
as in \cref{eq:diagonal-blocks},
that the derivative is formed from the 2
'diagonal blocks'.

\end{plSection}%{Affine registration}
%-----------------------------------------------------------------
\begin{plSection}{Euclidean registration}
\label{sec:euclidean-registration}

A {\it euclidean transform} is an affine transform
$\Vector{E} : \Reals^n \mapsto \Reals^n$,
$\Vector{E} \Vector{p} = \Vector{S} \Vector{p} + \Vector{t} $,
whose linear part is a scaled rotation:
$\Vector{S} = s \Vector{R}$,
where $s \in \Reals$ and $\Vector{R} : \Reals^n \mapsto \Reals^n$
is a rotation.

Euclidean transforms are easy to invert.

If $\Vector{E} = (\Vector{S},\Vector{t})$, then its inverse is
$\Vector{E}^{-1} = (\Vector{S}^{-1}, - \Vector{S}^{-1}\Vector{t})$.
The inverse of a rotation, $\Vector{R}$, is its adjoint
(tranpose) $\Vector{R}^{-1} = \Vector{R}^{\dagger}$.
The inverse of a scaled rotation $\Vector{S} = s \Vector{R}$
is therefore
$\Vector{S}^{-1} = (s \Vector{R})^{-1}
         = \frac{1}{s} \Vector{R}^{\dagger}
         = \frac{1}{s^2} \Vector{S}^{\dagger}$.
We can then write the inverse of a euclidean transform as
$\Vector{E}^{-1} = 
\frac{1}{s^2}(\Vector{S}^{\dagger}, 
- \Vector{S}^{\dagger}\Vector{t})$

Using quaternions, we can represent euclidean transforms with
7 dimensional points:
$\Vector{E} = (w_{\Vector{q}}, x_{\Vector{q}}, y_{\Vector{q}}, z_{\Vector{q}}, x_{\Vector{t}}, y_{\Vector{t}}, z_{\Vector{t}})$,
where $\Vector{q} = (w_{\Vector{q}}, x_{\Vector{q}}, y_{\Vector{q}}, z_{\Vector{q}})$ 
is a quaternion corresponding
to $\S$, the linear part of $\Vector{E}$,
and $\Vector{t} = (x_{\Vector{t}}, y_{\Vector{t}}, z_{\Vector{t}})$ is the translation part.

In the 7-dimensional representation, the inverse is:
\begin{equation}
\Vector{E}^{-1} =
\frac{1}{\| \Vector{q} \|_{\Set{Q}}^4}
\left(
\begin{array}{rcrcr}
& &  w_{\Vector{q}} & & \\
& & -x_{\Vector{q}} & & \\
& & -y_{\Vector{q}} & & \\
& & -z_{\Vector{q}} & & \\
(-w_{\Vector{q}}^2 - x_{\Vector{q}}^2 + y_{\Vector{q}}^2 + z_{\Vector{q}}^2)
x_{\Vector{t}}
&
-
&
2 (w_{\Vector{q}}z_{\Vector{q}} + x_{\Vector{q}}y_{\Vector{q}})
y_{\Vector{t}}
&
+
&
2 (w_{\Vector{q}}y_{\Vector{q}} - x_{\Vector{q}}z_{\Vector{q}})
z_{\Vector{t}}
\\
 2 (w_{\Vector{q}}z_{\Vector{q}} - x_{\Vector{q}}y_{\Vector{q}})
x_{\Vector{t}}
&
+
&
(-w_{\Vector{q}}^2 + x_{\Vector{q}}^2 - y_{\Vector{q}}^2 + z_{\Vector{q}}^2)
y_{\Vector{t}}
&
-
&
2 (w_{\Vector{q}}x_{\Vector{q}} + y_{\Vector{q}}z_{\Vector{q}})
z_{\Vector{t}}
\\
- 2 (w_{\Vector{q}}y_{\Vector{q}} + x_{\Vector{q}}z_{\Vector{q}})
x_{\Vector{t}}
&
+
&
2 (w_{\Vector{q}}x_{\Vector{q}} - y_{\Vector{q}}z_{\Vector{q}})
y_{\Vector{t}}
&
+
&
(-w_{\Vector{q}}^2 + x_{\Vector{q}}^2 + y_{\Vector{q}}^2 - z_{\Vector{q}}^2)
z_{\Vector{t}}
\end{array}
\right)
\end{equation}

In computing the gradients of registration penalties,
we sum expressions like
$\Derivative[\Vector{q}, \Vector{t}]{\left( \Vector{E}(\Vector{q},\Vector{t})\Vector{p}_i \right)}^{\dagger} \;
\Gradient[\Vector{p}_i]{f}$
(see \cref{eq:registration-gradient-sum}).
Using the results in sections
\ref{sec:Scaled-rotations}
and
\ref{sec:Shift-registration},
it's not hard to see that,
in terms of the partial derivative matrices,
this is:
\begin{equation}
\label{eq:euclidean-transform-gradient}
\left[
\Derivative[\Vector{q},\Vector{t}]{\; \Vector{E}(\Vector{q},\Vector{t})\Vector{p}_i}
\right]^{\dagger} \;
\Gradient[\Vector{p}_i]{f}
=
\left(
\begin{array}{c}
\left( \Derivative[w_{\Vector{q}}]{\Vector{S}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[x_{\Vector{q}}]{\Vector{S}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[y_{\Vector{q}}]{\Vector{S}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( \Derivative[z_{\Vector{q}}]{\Vector{S}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\end{array}
\right)
\oplus
\Gradient[\Vector{p}_i]{f}
\end{equation}

\end{plSection}%{Euclidean registration}
%-----------------------------------------------------------------
\begin{plSection}{Rigid registration}
\label{sec:rigid-registration}

A {\it rigid transform} is an affine transform
$\Vector{G} \Vector{p} = \Vector{R} \Vector{p} + \Vector{t} $,
whose linear part is a rotation, $\Vector{R}$.
Using the representation, $\Vector{R}(\Vector{q})$,
using {\em non-unit} quaternions,
presented in \cref{sec:Rotations},
we get the same results for the gradient terms
as in \cref{eq:euclidean-transform-gradient},
with the partials of $\Vector{S}(\Vector{q})$ replaced by the
partials of $\Vector{R}(\Vector{q})$, that is:
\begin{equation}
\label{eq:rigid-transform-gradient}
\left[
\Derivative[\Vector{q},\Vector{t}]
{\Vector{G}(\Vector{q},\Vector{t}) \Vector{p}_i}
\right]^{\dagger} \;
\Gradient[\Vector{p}_i]{f}
=
\left(
\begin{array}{c}
\left( 
\Derivative[w_{\Vector{q}}]{\Vector{R}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( 
\Derivative[x_{\Vector{q}}]{\Vector{R}(\Vector{q})}
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( 
\Derivative[y_{\Vector{q}}]{\Vector{R}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\left( 
\Derivative[z_{\Vector{q}}]{\Vector{R}(\Vector{q})} 
\; \Vector{p}_i \right) \bullet \Gradient[\Vector{p}_i]{f} \\
\end{array}
\right)
\oplus
\Gradient[\Vector{p}_i]{f}
\end{equation}
\end{plSection}%{Rigid registration}
%-----------------------------------------------------------------
\end{plSection}%{Transforms}
%-----------------------------------------------------------------
\end{plSection}%{Registration}
